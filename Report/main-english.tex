%Template by Mark Jervelund - 2015 - mjerv15@student.sdu.dk

\documentclass[a4paper,10pt,titlepage]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{ marvosym }
\usepackage{algpseudocode}
\usepackage[document]{ragged2e}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{datenumber}
\usepackage{venndiagram}
\usepackage{chngcntr}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{mathtools}
\newtheorem{theorem}{Theorem}

\usepackage{mathtools} % Bonus
\DeclarePairedDelimiter\norm\lVert\rVert
\setdatetoday
\addtocounter{datenumber}{0} %date for dilierry standard is today
\setdatebynumber{\thedatenumber}
\date{}
\setcounter{secnumdepth}{0}
\pagestyle{fancy}
\fancyhf{}
\title{<Course ID> <course name>}

\newcommand{\Z}{\mathbb{Z}}
\lhead{<Course id>}
\rhead{<Name> (<Student id)}
\rfoot{Page  \thepage \, of \pageref{LastPage}}
\counterwithin*{equation}{section}

\begin{document}
\begin{titlepage}
\centering
    \vspace*{9\baselineskip}
    \huge
    \bfseries
    <Title> \\
    \normalfont
    Mark Jervelund \\
    Mark@jervelund.com \\
    Doommius.com (Maybe change to m.jervelund.com or exclude ?) 	\\
    \vspace*{9\baselineskip}
    \normalfont
	\includegraphics[scale=1]{SDU_logo.png}
    \vfill\
    \vspace{5mm}
    Institute Of mathematics and Computer Science, SDU \\

	%Date
    \textbf{\datedate} \\[2\baselineskip]
\end{titlepage}

\renewcommand{\thepage}{\roman{page}}% Roman numerals for page counter
\tableofcontents
\newpage
\setcounter{page}{1}
\renewcommand{\thepage}{\arabic{page}}


\renewcommand*{\chapterpagestyle}{preamble}


  \section*{Abstract}

Databases allow modern society to store, manage and distribute data at a previously unprecedentedly scale. having data is a normal practice for most businesses, but it is often done monotonically on a single node, where modern needs require much high performance, storage, latency and  availability then current systems allow. Distributing a data store in a manner that scales performance, storage, availability and desire properties is no easy feat. In this Thesis i present methods of verifying these properties and investigate how different frameworks solve this issue, or often workaround the issue in a way that aligns with the requirements of the systems. \\

Within the framework of the thesis i present methods of verifying the ACID properties, How these properties were solved in the past, How it can and is solved today, what trade offs some systems have made, and a analysis of modern database uses cases and whether they require the ACID properties to solve issues.\\

First, I Present ACID, It's constraints, what faults occur in both database systems, how their manifests themselves, whats the underlying causes often are for these faults, and what limits the ACID properties imposes on a given system, what relaxations we can introduce to a system to still gain the same result but where we might allow conditional or future commits, eventual consistency, some degree of data-loss, dirty reads, and other relaxations in a given system.\\

Then, I Present Jepsen, a CLojure framework\cite{Jepsen} developed by K. Kingsbury that allow for testing of distributed systems, This is solved via a direct serialization graph (DSG) and queries to the target system that are carefully chosen that allows for traceability, and recoverability.  \\


Then, I present Azure Service Fabric(SF), SF is a distributed container orchestration system made my Microsoft, that allows for hosting of services, or apps. It includes a few different built in functions, but the primary interest here lie within the reliable containers aspect of SF, and what claims Microsoft makes concerning the behaviour of this data.\\

Then, I will present what modern database systems promise, what properties of ACID they follow, which they relax, and which they disregard, and well as what they gain, and which tradeoffs they endure.\\

Then i will design, and attempt to implement and execute a Jepsen test against service Fabrics reliable containers, and compare these results to the claims Microsoft has made.\\

Finally, I will present how the ACID properties compare to modern uses cases of databases, do we need to follow them strictly or can simply disregard them in some uses cases? What are the exceptions, and what is there to gain ?\\
\\



\chapter{Introduction}

Highly Distributed systems are becoming more and more common as the world grows evermore interconnected, faster paced, increasing data driven with higher expectations of services and product. where the end user expects reliability, availability combined with low- latency and cost, How do we guarantee this is a distributed system that spans the planet. Is it even possible to get both, and is it even needed in most use cases?\\

Most people are familiar with how YouTube, Facebook, Google and Reddit behave and what quirks they sometimes present, Most people remember the YouTube video counter that got stuck and only update once a day or where depending on which endpoint you connected to you were given a different numbers. These are both examples of induce eventual consistency. Here it might be that you are seeing different comments on posts depending on what region you connect from, but eventually both pages will reach consistency, 

We can also typeset \verb|<text>verbatim text</text>|.
Backticks are also rendered correctly: \verb|`words in backticks`|.





\section{ACID Properties}








\subsection{Introduction}
"
Jepsen is an effort to improve the safety of distributed databases, queues, consensus systems  (...) exploring particular systems’ failure modes. In each analysis we explore whether the system lives up to its documentation’s claims.
"\cite{jepsonio}
\\

Going from the above quite Jepsen is a way that allows us to check whether a given database system lives up to the requirements and premises that are given, and in a world where distributed, hyper scale or even planetary scale systems are becoming the norm the way data storage is done is required to behave in an expected manner, the reason that expected manner is used rather than correct manner is that we may allow certain faults to occur and eventual consistency to allow for higher throughput applications and that some data may only be required locally as to consider a transaction complete even in the case where some undesirable conditions occur, but these are tolerated to a certain extent. //

Two different examples of this is the YouTube 301 views that happened around 2015, where the number of views weren't globally distributed right away. while comments and likes were, this meant two things. //

Comments were available globally in real time, while views would also commit globally doing low load times, or off hours to maximize utilization of resources.

another more modern scenario where the real time data distribution and correctness is of the utmost importance is within transactions in the finance industry,  where we only want to consider a financial transaction committed once all shards of this data is replicated and the 'old' balance is non longer available, otherwise we could reach a condition where worst case a client is able to draw a negative balance on their account or where one of the transactions isn't recorded as only one of the two transactions is recorded.//

To go more in debt about these cases we need to do a short introduction to isolation levels and the pheomena that they can cause.


\subsection{Isolation levels and phenomena}

The Isolation level as defined by the ISO/IEC 9075 standard which defines SQL, This means that any database system should present to what level that they follow the isolation levels. in this we have 4 levels that can lead to unintended behavior within a single transaction. 

First the 3 types of behavior is explained as these are used to explain the 4 levels of isolation. the are categorized as the 3 below.
\begin{itemize}
\item dirty read,
\item Non-repeatable read and
\item Phantom read
\end{itemize}

'Dirty read' is when a S1 can read data that S2 has written but not yet committed, It is considered dirty as S2 can rollback the transaction where S1 read data that must be considered non existent. \textcolor{red}{Make example diagram} 
\\
The second case of 'Non-repeatable read' is when S1 reads data that is changed by S2 and committed. so if S1 read the some data again they will have changed. this results in two equal select statements returning different results.  \textcolor{red}{Make example diagram} 

Phantom read
The Third and last type is phantom read which is a special case of non-repeatable read that occurs when S1 reads data where a where condition is used to specify what data we want. After this initial read, a second session S2 inserts data that meets S1's where condition and commits the data. When S1 issues a select statement with the same where condition, it finds new records. It is called phantom read because the new records seem to be of phantom origin.
 \textcolor{red}{Make example diagram} 

The 4 Isolation levels are defined as:
read uncommitted
       The read uncommitted does not issue shared lock, which allows session S2 write access to the data S1 is reading.\textcolor{red}{write more in dept} 
 read commited
 \textcolor{red}{write more in dept} 
repeatable read
\textcolor{red}{write more in dept} 
serializable
\textcolor{red}{write more in dept} 



From this knowledge a table can be made that gives us an overview of the isolation levels and what behaviour and the trade off they have.
Isolation level	Read phenomena
Dirty read	Non-repeatable read	Phantom read
read uncommitted	yes	yes	yes
read committed	no	yes	yes
repeatable read	no	no	y
serializable	no	no	no
\textcolor{red}{Maybe also include something about snapshot isolation} 


\subsection{Modern Database systems, and the trade offs they make.}


Atomicity, and Isolation as we often write the data to a arbitrary node, that accepts after the data has been distributed outside of it's rack, availability zone or region. and where the newest timestamp then overrules all other written data without care of data on other nodes which can breaks Atomicity, and Isolation, as a check and set(CAS), or update statement might uses stale data and due to it's newer timestamp any data written in the meantime gets discarded. Solutions here might require waiting for full distribution of any data prior to the query executing, but this would drastically slow down the entire system. This does however not factor in issues related to system faults
"""

\subsection{Historically}

Historically this was done with using a manually defined hand coded set of patterns to check how a system behaves wrt to the isolation levels above, like if some proven invariants hold, or if an anomaly is present in parallel is present by inserting record x and y in two separate transactions and and in two more transactions checking if we can observe x but not y, or y and not x, as this could show how the systems handles long forks and snapshot isolation, and more importantly if it supports it at all.

these checking are generally quite efficient and run in polynomial time, but they only check for a certain patterns and therefor don't give us the larger picture of where issues are present, and only cover a fairly limited set of configurations and isolation levels, and are defined on a system to system basis and no interchangeability is supporter.

This means that this has been a giant scope project where case by case tests are predefined and where we only test for certain scopes, which more importantly mean that tests have been done but the test coverage haven't been perfect and a lot of anomalies are never detected.

\textcolor{red}{Need to add some more to this section, add examples are past test, diagrams, papers etc}

\subsection{State of the art.}

The State of the art is Jepsen, or rather one of the State of the Art projects.

Jepsen supports quite a few different modules but the most power full features goes by the name Elle, inferring isolation anomalies from Experimental Observations. \\

The way this works is be inferring a dependency graph between client side observations and the database version history. This is done by carefully selecting database objects and operations such that the database reads reveals information about the version history. 

this means that Elle is able to reveal any anomaly and provide a concise explanation as to why a fault occurred with information of what conditions were present to cause this fault to occur. Using this information we are able to say how a system behaves, what level of isolation and which behavior we'll see as well as what promises the system makes and how does promises are reflected in reality.

And these things can be manifested in multiple ways, some cases are as mentioned earlier in the paper accepted as eventually consistency and performance is valued higher or some applications where loosing some data points are acceptable to allow for higher write throughput.

and the same does for stale, dirty, non-repeatable and phantom reads aren't an issue. this could be on hyper scale social networks where if you see something that was deleted, or if the newest posts, comments and likes aren't distributed across the all notes, but they will eventually. but this is a trade off that is done to allow for much higher write performance as the chance a user is making chancing to the same page on two different nodes/clusters are minimal and the required performance drop required to facilitate the guarantee that all data is always up to date would mean that the system wouldn't scale at the rate it's required, this also brings up another interesting topic, approximate programming, where a program doesn't always have to return the correct output, but if we can see a magnitude speedup of a program and accept a faulty result rate of a few \%, then the cost saving and capacity increase could very much be worth it. this could be in the case of Netflix and amazon recommencing products and services, it doesn't have to be perfect and maybe sometimes the result is wrong but if it means we're able to serve a lot more customers before having to degrade services or maybe having it as a step in the service degradation levels to support as many users as possible. \\

but a lot of this lay outside the scope of this thesis but it's also a super interesting field that will probably see grow in the next decade.





\subsection{Past jepsen tests}

https://aphyr.com/posts/294-call-me-maybe-cassandra


https://aphyr.com/posts/291-call-me-maybe-zookeeper







\subsection{methods used in Jepsen tests}

\subsection{related work to Jepsen}


K. Kingsbury. Knossos.
https://github.com/jepsen-io/knossos, 2013-2019.

G. Lowe. Testing and Verifying Concurrent Objects.
Concurrency and Computation: Practice and
Experience, 29(4), 2017

J. M. Wing and C. Gong. Testing and Verifying
Concurrent Objects. Journal of Parallel and
Distributed Computing, 17(1-2), 1993.

P. B. Gibbons and E. Korach. Testing shared
memories. SIAM Journal on Computing, 26(4), 1997

S. Burckhardt, C. Dern, M. Musuvathi, and R. Tan.
Line-up: A Complete and Automatic Linearizability
Checker. PLDI ’10, 2010.


\section{Service Fabric}

\subsection{Introduction}

Service Fabric (SF) is a presented as a distributed systems platform something akin to Kubernetes (K8S), where the user is able to build, deploy and scale micro services and containers, one of the key points presented by on Azure Service Fabric is that you're able to run stateful services. It's presented by Microsoft as the backbone of their core services and data stores.


\subsection{DataStore}

So as mentioned above Service Fabric Contains stateful services, these use reliable collections that are in memory storage 



\subsection{Promises}


\subsection{Configuration}


What we are able to tweak


\subsection{What aspects of the service fabric are we  we'd like to test}

Reliable collections.

\subsection{What does service Fabric promise wrt ACID}

https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-reliable-collections-transactions-locks


\section{Experiment}

\subsection{Designing the experiment}

\subsection{Development}

\subsection{Issues}

Linux and windows versions being far from interchangeable and applications and services that function on windows/local machines fail crash on deployed cluster

visual studio being unable to load .dmp files to debug crashed applications from the cloud.

Visual studio remote debugger not working

\subsubsec{Azuer}

Configuration issues,

Cluster cecoming unhealty/corrupt and nodes not being configred correctly after a reimage.

\subsection{Introduction}

The Goal of the experiment to to investigate weather Service Fabric is compliance with ACID or not,


\subsection{Tooling}


%LaTeX hints are provided in \cref{chap:latexhints}.

%\blinddocument

\chapter{Related Work}

\chapter{Conclusion and Outlook}
\section*{Conclusion}

\section*{Outlook}

\printbibliography

All links were last followed on March 17, 2018.



\newpage
\appendix
\input{Proposal}

\section{Schedule}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}

\begin{tabular}{clll}
\multicolumn{2}{l}{Mark Jervelund thesis plan} &                                           &                  \\
                                & Week 45      &                                             &                                                                                                                            \\
                                & Week 46      &                                             & \multirow{-2}{*}{Study Jensen test}                                                                                        \\
                                & Week 47      &                                             &                                                                                                                            \\
\multirow{-4}{*}{November}      & Week 48      &                                             & \multirow{-2}{*}{Finish study on Jepsen test}                                                                              \\
                                & Week 49      &                                             &                                                                                                                            \\
                                & Week 50      &                                             & \multirow{-2}{*}{Study Service Fabric}                                                                                     \\
                                & Week 51      &                                             &                                                                            \\
                                & Week 52      &                                             & \multirow{-2}{*}{ Christmas break}                                            \\
\multirow{-5}{*}{December}      & Week 53      &                                             &                                                                                                                            \\
                                & week 01      &  \multirow{-10}{*}{Structured study 8 weeks} & \multirow{-2}{*}{Finish Study Service Fabric}                                                                              \\
                                & Week 02      &                                             &                                                                                                                            \\
                                & Week 03      &                                             & \multirow{-2}{*}{designing the experiment}                                                                                 \\
\multirow{-4}{*}{January}       & Week 04      &                                             &                                                                                                                            \\
                                & Week 05      &                                             & \multirow{-2}{*}{designing the experiment}                                                                                 \\
                                & Week 06      &                                             &                                                                                                                            \\
                                & Week 07      &                                             & \multirow{-2}{*}{Execute the experiment}                                                                                   \\
\multirow{-4}{*}{February}      & Week 08      &                                             &                                                                                                                            \\
                                & Week 09      &                                             & \multirow{-2}{*}{Analyse the experiment}                                                                                   \\
                                & Week 10      &                                             &                                                                                                                            \\
                                & Week 11      &  \multirow{-10}{*}{Experiment 10 weeks}     & \multirow{-2}{*}{discover what the findings from the experiment is}                                                         \\
                                & Week 12      &                                             &                                                                                                                            \\
\multirow{-5}{*}{March}         & Week 13      &                                             & \multirow{-2}{*}{Running additional experiments if needed  Full on write mode} \\
                                & Week 14      &                                             &                                                                                                                            \\
                                & Week 15      &                                             & \multirow{-2}{*}{Full on write mode}                                                                                       \\
                                & Week 16      &                                             &                                                                                                                            \\
\multirow{-4}{*}{April}         & Week 17      &                                             & \multirow{-2}{*}{Full on write mode}                                                                                       \\
                                & Week 18      &                                             &                                                                                                                            \\
                                & Week 19      &                                             & \multirow{-2}{*}{Full on write mode    Send out thesis for feedback}             \\
                                & Week 20      &                                             &                                                                                                                            \\
                                & Week 21      & \multirow{-10}{*}{Thesis writing  10 weeks} & \multirow{-2}{*}{Correction}                                                                                               \\
\multirow{-5}{*}{May}           & Week 22      &                                             &                                                                                                                            \\
                                & Week 23      & \multirow{-2}{*}{goal}                      & \multirow{-2}{*}{Hand in}                                                                                                  \\
                                & Week 24      & \multicolumn{1}{l}{}                        & \multicolumn{1}{l}{}                                                                                                       \\
                                & Week 25      &  \multicolumn{1}{l}{}                       & \multicolumn{1}{l}{}                                                                                                       \\
                                & Week 26      &  \multicolumn{1}{l}{}                       & \multicolumn{1}{l}{}                                                                                                       \\
\multirow{-5}{*}{June}          & Week 27      & \multicolumn{1}{l}{}                        & \multicolumn{1}{l}{}                                                                                                       \\
\multicolumn{1}{l}{}            & Week 28      & \multicolumn{1}{l}{}                        & \multicolumn{1}{l}{}                                                                                                       \\
\multicolumn{1}{l}{}            & Week 29      & \multicolumn{1}{l}{}                        & \multicolumn{1}{l}{}                                                                                                       \\
\multicolumn{1}{l}{}            & Week 30      & \multicolumn{1}{l}{}                        & \multicolumn{1}{l}{}                                                                                                       \\
\multicolumn{1}{l}{}            & Week 31      & \multicolumn{1}{l}{}                        & \multicolumn{1}{l}{}                                                                                                      
\end{tabular}




%\input{latexhints-english}

\pagestyle{empty}
\renewcommand*{\chapterpagestyle}{empty}





\chapter{Needs to be relocated}


\section{Things to read(temp list)}

https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf

https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-reliable-collections




\section{Jepsen}

\end{document}
